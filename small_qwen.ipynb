{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e2204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df20673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "from dataset.countdown_dataloader import Countdown\n",
    "from dataset.countdown_utils import ( gen_dataset, compute_metrics, batch_compute_metrics )\n",
    "from grpo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fba54f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f29d9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5edcef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save a tiny dataset with 5 samples\n",
    "dataset_json_path = \"simpler_countdown_data.json\"\n",
    "gen_dataset(num_samples=5, num_operands=3, max_target=100, max_number=15, save_path=dataset_json_path)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = Countdown(dataset_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9610e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Initialize the model with empty weights if needed\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c98b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch out dataset\n",
    "batch_size = 3\n",
    "batch_raw = dataset.get_batch(batch_size)\n",
    "\n",
    "# Combine whole dataset into prompts\n",
    "batch = [\n",
    "  f\"Using the numbers {item[\"numbers\"]}, create an equation that equals {item[\"target\"]}. Box your answer.\" \n",
    "  for item in batch_raw\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "154f5a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    }
   ],
   "source": [
    "# Use grpo sample outputs function\n",
    "outputs_ids, outputs = sample_outputs(\n",
    "    policy=model,\n",
    "    tokenizer=tokenizer,\n",
    "    query_batch=batch,\n",
    "    G=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7b40a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 12:39:23,731 - INFO - Rewards tensor shape: torch.Size([3, 3])\n",
      "2025-04-07 12:39:23,731 - INFO - Accuracies tensor shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Calculate rewards for outputs\n",
    "rewards, accuracies = batch_compute_metrics(\n",
    "    outputs,\n",
    "    queries=batch_raw\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02b8d86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Using the numbers [1, 2, 4], create an equation that equals 5. Box your answer.\n",
      "Output: ['(5 pts)\\n\\\\[\\\\boxed{2+1+4=5}\\\\]', 'Can you solve it? [1, 1] * [2, 4]\\n\\nYes, I can use this equation to create an answer box:\\n\\n1.  [1, 1] * [2, 4] = 2\\n2. 1 * [2, 4] = ', 'What numbers would you use to create this?\\nTo create an equation on the numbers {1, 2, 4} that equals 5, you can multiply 1 by 2 and 4 to get 2x2 = 4. Then you can add 1 to 2 to get 1']\n",
      "Reward: tensor([0.1000, 0.1000, 0.1000])\n",
      "Accuracy: tensor([0., 0., 0.])\n",
      "--------------------\n",
      "Input: Using the numbers [14, 6, 10], create an equation that equals 46. Box your answer.\n",
      "Output: ['  (Hint: use a multiplication, addition and subtraction operation, no division.) To create an equation that equals 46 using the numbers [14, 6, 10], we can use multiplication, addition, and subtraction. Here are a few possible equations:\\n\\n\\\\[ 14 \\\\times 6', ' Certainly! You want to create an equation using three numbers from the list: [14, 6, 10], such that when these numbers are combined into an algebraic equation, the result is 46. Hereâ€™s one way to do it:\\n\\n\\\\[ 10x + 14y', ' 1.388888889\\n\\nExplanation used: The equation that equals 46 using the given numbers [(2, 2, 2)]\\n\\nCalculation steps used:\\n1. First, we need to find the square root of the number 14, which is (sqrt{']\n",
      "Reward: tensor([0., 0., 0.])\n",
      "Accuracy: tensor([0., 0., 0.])\n",
      "--------------------\n",
      "Input: Using the numbers [11, 2, 10], create an equation that equals 88. Box your answer.\n",
      "Output: [\" You can start by attempting several different combinations to find a solution. Remember that sometimes addition might not work as expected, so it's better to check multiple combinations instead of always trusting the first one. If you're stuck, consider solving the problem step by step and keeping track of your progress.\\nSure! We can create a\", ' To create an equation that equals 88 using the numbers [11, 2, 10], we can use a variety of operations. Here is one possible solution:\\n\\n1. Multiply 11 by 10: 10 * 10 = 100\\n2. Add', ' [Let the first number be X. The first number is X+2, the second number is X, and the third number is equal to 8. The original number is equal to 11 + 2 + 8 = 21.]']\n",
      "Reward: tensor([0.0000, 0.1000, 0.1000])\n",
      "Accuracy: tensor([0., 0., 0.])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the outputs and rewards\n",
    "for i, output in enumerate(outputs):\n",
    "    print(f\"Input: {batch[i]}\")\n",
    "    print(f\"Output: {output}\")\n",
    "    print(f\"Reward: {rewards[i]}\")\n",
    "    print(f\"Accuracy: {accuracies[i]}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03527a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute GRPO advantage\n",
    "advantage = calculate_grpo_advantage(\n",
    "    rewards\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "242e731e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advantage: tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-1.1547,  0.5774,  0.5774]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Advantage: {advantage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa5082b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log probabilities\n",
    "log_probs = compute_log_probs(\n",
    "    policy=model,\n",
    "    tokenizer=tokenizer,\n",
    "    query_batch=batch,\n",
    "    generated_ids=outputs_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecc2c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 12:51:48,160 - INFO - Final objective shape: torch.Size([3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRPO Objective: tensor([ 0.0000e+00,  0.0000e+00, -9.9341e-09], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate GRPO objective\n",
    "grpo_objective = calculate_grpo_objective(\n",
    "    model_log_probs=log_probs,\n",
    "    old_model_log_probs=log_probs,  # Assuming old model is the same for this example\n",
    "    ref_model_log_probs=log_probs,  # Assuming ref model is the same for this example\n",
    "    advantages=advantage,\n",
    "    eps=0.1,  # Epsilon for clipping\n",
    "    beta=0.05,  # Beta for the objective function\n",
    ")\n",
    "\n",
    "print(f\"GRPO Objective: {grpo_objective}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99518bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e35d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m updated_policy = grpo_iteration(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     query_batch_prompts=\u001b[43mbatch\u001b[49m,\n\u001b[32m      3\u001b[39m     query_batch_raw=batch_raw,\n\u001b[32m      4\u001b[39m     policy_model=model,\n\u001b[32m      5\u001b[39m     reference_model=model,  \u001b[38;5;66;03m# Assuming reference model is the same for this example\u001b[39;00m\n\u001b[32m      6\u001b[39m     reward_model=batch_compute_metrics,\n\u001b[32m      7\u001b[39m     tokenizer=tokenizer,\n\u001b[32m      8\u001b[39m     optimizer=optimizer,\n\u001b[32m      9\u001b[39m     G=\u001b[32m3\u001b[39m,\n\u001b[32m     10\u001b[39m     eps=\u001b[32m0.1\u001b[39m,  \u001b[38;5;66;03m# Epsilon for clipping\u001b[39;00m\n\u001b[32m     11\u001b[39m     beta=\u001b[32m0.05\u001b[39m,  \u001b[38;5;66;03m# Beta for the objective function\u001b[39;00m\n\u001b[32m     12\u001b[39m     mu=\u001b[32m3\u001b[39m\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "updated_policy = grpo_iteration(\n",
    "    query_batch_prompts=batch,\n",
    "    query_batch_raw=batch_raw,\n",
    "    policy_model=model,\n",
    "    reference_model=model,  # Assuming reference model is the same for this example\n",
    "    reward_model=batch_compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizer=optimizer,\n",
    "    G=3,\n",
    "    eps=0.1,  # Epsilon for clipping\n",
    "    beta=0.05,  # Beta for the objective function\n",
    "    mu=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grpo-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
