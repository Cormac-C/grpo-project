{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e2204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df20673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cormaccureton/mambaforge/envs/grpo-proj/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "from dataset.countdown_dataloader import Countdown\n",
    "from dataset.countdown_utils import ( gen_dataset, compute_metrics, batch_compute_metrics )\n",
    "from grpo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fba54f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f29d9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5edcef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save a tiny dataset with 5 samples\n",
    "dataset_json_path = \"simpler_countdown_data.json\"\n",
    "gen_dataset(num_samples=5, num_operands=3, max_target=100, max_number=15, save_path=dataset_json_path)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = Countdown(dataset_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9610e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Initialize the model with empty weights if needed\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c98b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch out dataset\n",
    "batch_size = 3\n",
    "batch_raw = dataset.get_batch(batch_size)\n",
    "\n",
    "# Combine whole dataset into prompts\n",
    "batch = [\n",
    "  f\"Using the numbers {item[\"numbers\"]}, create an equation that equals {item[\"target\"]}. Box your answer.\" \n",
    "  for item in batch_raw\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "154f5a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    }
   ],
   "source": [
    "# Use grpo sample outputs function\n",
    "outputs_ids, outputs = sample_outputs(\n",
    "    policy=model,\n",
    "    tokenizer=tokenizer,\n",
    "    query_batch=batch,\n",
    "    G=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7b40a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 12:56:53,370 - INFO - Rewards tensor shape: torch.Size([3, 3])\n",
      "2025-04-07 12:56:53,370 - INFO - Accuracies tensor shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Calculate rewards for outputs\n",
    "rewards, accuracies = batch_compute_metrics(\n",
    "    outputs,\n",
    "    queries=batch_raw\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b8d86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Using the numbers [1, 2, 4], create an equation that equals 5. Box your answer.\n",
      "Output: [\"Explain how a negative result was avoided and explain your reasoning. Let's create an equation using only the numbers [1, 2, 4] and try to solve it manually. We'll first attempt to use each number individually and see if we can reach 5.\\n\\n1. **First Try:**\\n  \", \"If you're unsure which numbers go where, look at 1, 2, and 4 as the answer.\\nTo create an equation that equals 5 using the numbers 1, 2, and 4 as the answer, you can form one of the six permutations of these three digits as follows:\\n\\n1\", 'Human beings are only humans, but are not necessarily animals.\\nHuman logic\\nAn important conclusion would be human are animals but not all animals are humans\\nHow old do i have to be for my mom to ask me about the sun ? (0-100) A man is a human and not always a male']\n",
      "Reward: tensor([0., 0., 0.])\n",
      "Accuracy: tensor([0., 0., 0.])\n",
      "--------------------\n",
      "Input: Using the numbers [14, 6, 10], create an equation that equals 46. Box your answer.\n",
      "Output: [' Here is one possible equation that satisfies the condition:\\n\\n14 (square) + 6 (square) + 10 (square) = 46\\n\\n14^2 + 6^2 + 10^2 = 46^2\\n\\nThe equation with the greatest value for x is', ' Here is an equation that equals 46 using the numbers [14, 6, 10]:\\n\\n\\\\[ 14 = 6 + 6 + 6 \\\\]\\n\\nThis is because:\\n\\n\\\\[ 6 + 6 + 6 = 18 \\\\]\\n\\nAnd since:\\n\\n\\\\[ 18', \" Let's try different combination of numbers.\\n\\nAfter trying a few combinations, I thought this one works.\\n\\n2*4 + 6 + 10*4 = 46 (since 10*4=40)\"]\n",
      "Reward: tensor([0.1000, 0.1000, 0.1000])\n",
      "Accuracy: tensor([0., 0., 0.])\n",
      "--------------------\n",
      "Input: Using the numbers [11, 2, 10], create an equation that equals 88. Box your answer.\n",
      "Output: [\" To find an equation that equals 88 using the numbers [11, 2, 10], I need to find a combination of addition and multiplication of these two given numbers. One mathematical operation that could be used is the sum and product of the numbers. \\n\\nHere's a step-by-step process to\", ' To create an equation with the numbers [11, 2, 10] that equals 88, you can use a variety of arithmetic operations (addition, subtraction, multiplication, division, etc.) and can include parentheses to clarify the order of operations. Here are a few ways to do it:\\n\\n', ' 88 = 11*8 + 2 + 10\\n88 = 88']\n",
      "Reward: tensor([0.0000, 0.0000, 0.1000])\n",
      "Accuracy: tensor([0., 0., 0.])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the outputs and rewards\n",
    "for i, output in enumerate(outputs):\n",
    "    print(f\"Input: {batch[i]}\")\n",
    "    print(f\"Output: {output}\")\n",
    "    print(f\"Reward: {rewards[i]}\")\n",
    "    print(f\"Accuracy: {accuracies[i]}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03527a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute GRPO advantage\n",
    "advantage = calculate_grpo_advantage(\n",
    "    rewards\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "242e731e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advantage: tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.5774, -0.5774,  1.1547]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Advantage: {advantage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa5082b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log probabilities\n",
    "log_probs = compute_log_probs(\n",
    "    policy=model,\n",
    "    tokenizer=tokenizer,\n",
    "    query_batch=batch,\n",
    "    generated_ids=outputs_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ecc2c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRPO Objective: tensor([ 0.0000e+00,  0.0000e+00, -1.9868e-08], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate GRPO objective\n",
    "grpo_objective = calculate_grpo_objective(\n",
    "    model_log_probs=log_probs,\n",
    "    old_model_log_probs=log_probs,  # Assuming old model is the same for this example\n",
    "    ref_model_log_probs=log_probs,  # Assuming ref model is the same for this example\n",
    "    advantages=advantage,\n",
    "    eps=0.1,  # Epsilon for clipping\n",
    "    beta=0.05,  # Beta for the objective function\n",
    ")\n",
    "\n",
    "print(f\"GRPO Objective: {grpo_objective}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c99518bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e35d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "2025-04-07 12:57:07,871 - INFO - Rewards tensor shape: torch.Size([3, 3])\n",
      "2025-04-07 12:57:07,875 - INFO - Accuracies tensor shape: torch.Size([3, 3])\n",
      "2025-04-07 12:57:21,714 - INFO - Update iteration: 1/3\n",
      "2025-04-07 12:57:29,404 - INFO - Loss: 3.311369312086754e-08\n"
     ]
    }
   ],
   "source": [
    "updated_policy = grpo_iteration(\n",
    "    query_batch_prompts=batch,\n",
    "    query_batch_raw=batch_raw,\n",
    "    policy_model=model,\n",
    "    reference_model=model,  # Assuming reference model is the same for this example\n",
    "    reward_model=batch_compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizer=optimizer,\n",
    "    G=3,\n",
    "    eps=0.1,  # Epsilon for clipping\n",
    "    beta=0.05,  # Beta for the objective function\n",
    "    mu=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grpo-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
